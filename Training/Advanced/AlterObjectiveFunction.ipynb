{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Altering the objective function and comparing calibrations\n",
    "\n",
    "\n",
    "Workbook layout:\n",
    "   1. Read historical benchmarking streamflow data from csv and get shapefile information\n",
    "   2. Calibrate using standard Nash-Sutcliffe Efficiency (NSE) objective function and added Kling-Gupta Efficiency (KGE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   1. Read shapefile and historical data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get catchments shapes and IDs used for benchmarking from shapefile\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from awrams.benchmarking.utils import read_id_csv\n",
    "from awrams.utils import config_manager\n",
    "from awrams.utils.io.data_mapping import SplitFileManager\n",
    "from awrams.utils.gis import ShapefileDB\n",
    "\n",
    "system_profile = config_manager.get_system_profile()\n",
    "system_settings = system_profile.get_settings()\n",
    "\n",
    "base_data_path = system_settings['DATA_PATHS']['BASE_DATA']\n",
    "catchment_shapefile = os.path.join(base_data_path, 'spatial/shapefiles/Final_list_all_attributes.shp')\n",
    "\n",
    "catchments = ShapefileDB(catchment_shapefile)\n",
    "records = catchments.get_records_df()\n",
    "records['StationID'].head()\n",
    "\n",
    "catchment_csv = base_data_path + '/training/benchmarking/catchment_ids.csv'\n",
    "id_list = read_id_csv(catchment_csv)\n",
    "\n",
    "obs_csv = base_data_path + '/observations/runoff/awrams_v5_cal_qobs.csv'\n",
    "qobs = pd.read_csv(obs_csv, index_col=0)\n",
    "\n",
    "# get site ids and start dates etc for comparison\n",
    "ids = records['StationID']  # ids as used in awra-l system (often concatenated wrsc)\n",
    "wrsids = records['WrscID'] # official water resource station catalogue station numbers\n",
    "areas = records['AlbersArea'] # catchment areas in km^ 2\n",
    "findate = records['DateQfinish'] # finish date\n",
    "startdate = records['DateOpen'] # start date "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Demonstrate use of altered objective function\n",
    "## Calibrate AWRA-L to a few catchments using NSE and then the Kling-Gupta Efficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from awrams.calibration import cluster, support\n",
    "from awrams.calibration.launch_calibration import run_from_pickle\n",
    "from awrams.calibration.objectives import test_objectives as tobj\n",
    "from awrams.calibration.optimizers import sce\n",
    "from awrams.models.awral.model import AWRALModel\n",
    "from awrams.utils import extents, gis\n",
    "from awrams.utils import datetools as dt\n",
    "from awrams.utils.nodegraph import nodes, graph\n",
    "\n",
    "# Get model settings for the AWRA-L model\n",
    "model_profile = config_manager.get_model_profile('awral', 'v6_default')\n",
    "model_settings = model_profile.get_settings()\n",
    "\n",
    "# Define the extenst of the calibration\n",
    "def_extent = extents.get_default_extent() \n",
    "# define the location of input data (streamflow and climate)\n",
    "cal_catchments=['105001','145003'] # set of 4 test data sites provided with git copy\n",
    "\n",
    "input_map = model_profile.get_input_mapping()\n",
    "\n",
    "## Create a dict with multiple extents\n",
    "cal_dict = {}\n",
    "#cal_catchments=['113004','111101', '109001', '108003', '112102', '107002','105001', '116008']\n",
    "#observations = dict(qtot = '../../test_data/calibration/q_obs.csv' ) - if only have limited observations\n",
    "observations=dict(qtot=obs_csv)\n",
    "for catchment in cal_catchments:\n",
    "    cal_dict[catchment] = catchments.get_extent_by_field('StationID', catchment.zfill(6), parent_extent=def_extent)\n",
    "\n",
    "run_period = dt.dates('2009 - 2010')\n",
    "eval_period = dt.dates('2009 - 2010')\n",
    "print('Calibrating over the following set of sites for 2009-2010',cal_dict)\n",
    "evolver_spec = support.EvolverSpec(sce.CCEvolver,\n",
    "                                   evolver_run_args=dict(n_offspring=1,n_evolutions=5,elitism=2.0))\n",
    "optimizer_spec = support.OptimizerSpec(sce.ShuffledOptimizer,\n",
    "                                       evolver_spec=evolver_spec,\n",
    "                                       n_complexes=5,\n",
    "                                       max_nsni=500,\n",
    "                                       min_complexes=1,\n",
    "                                       max_eval=2000) #n_complex 14\n",
    "local_objfspec = support.ObjectiveFunctionSpec(tobj.TestLocalSingle)  # this function to load up the ObjFunc comes from awrams.calibration.support\n",
    "global_objfspec = tobj.TestGlobalSingle\n",
    "objective_spec = support.ObjectiveSpec(global_objfspec,\n",
    "                                       local_objfspec,\n",
    "                                       observations,\n",
    "                                       eval_period)\n",
    "#### 2.6. Build spec dict\n",
    "#Assemble above settings into specification dictionary\n",
    "# Get the input mapping and model\n",
    "awral = model_profile.get_model(model_settings)\n",
    "node_mapping = input_map\n",
    "model = awral#callable_to_funcspec(awral)\n",
    "cal_spec = {}\n",
    "cal_spec['optimizer_spec'] = optimizer_spec\n",
    "cal_spec['objective_spec'] = objective_spec\n",
    "cal_spec['extent_map'] = cal_dict\n",
    "cal_spec['run_period'] = run_period\n",
    "cal_spec['model'] = model\n",
    "cal_spec['node_mapping'] = node_mapping\n",
    "cal_spec['logfile'] = './calres.h5'\n",
    "\n",
    "ncores = 4\n",
    "nnodes = 1\n",
    "cluster.build_pickle_from_spec(cal_spec, ncores, nnodes, 'test_cal.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can skip this step and read in outputs as it takes a little while\n",
    "#### results saved in './calres.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the calibration\n",
    "#from awrams.calibration.launch_calibration import run_from_pickle\n",
    "import time\n",
    "start = time.time()\n",
    "print(\"Starting calibration........\")\n",
    "cal = run_from_pickle('./test_cal.pkl')\n",
    "end = time.time()\n",
    "print('Calibration complete.......')\n",
    "print('Time elapsed for calibration',end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = support.CalibrationResults('./calres.h5')\n",
    "cr.get_best_paramset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alter the objective function\n",
    "\n",
    "#### View objective function file [calibration/objectives/test_objectives.py]\n",
    "\n",
    "[calibration/objectives/test_objectives.py]: ../../../edit/calibration/awrams/calibration/objectives/test_objectives.py                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View current objective function...\n",
    "# Code below is from within test_objectives.py\n",
    "from awrams.calibration.support import input_group\n",
    "\n",
    "class TestLocalSingle:\n",
    "\n",
    "    input_schema = input_group(['qtot'])\n",
    "    output_schema = ['qtot_nse']\n",
    "\n",
    "    def __init__(self,obs,eval_period,min_valid=15):\n",
    "\n",
    "        self.valid_idx = {}\n",
    "        self.nse = {}\n",
    "        self.flow_variable = 'qtot'\n",
    "        for k in [self.flow_variable]:\n",
    "\n",
    "            data = obs[k]\n",
    "\n",
    "            if np.isnan(data).any():\n",
    "                nan_mask = np.isnan(data)\n",
    "                self.valid_idx[k] = np.where(nan_mask == False)\n",
    "            else:\n",
    "                self.valid_idx[k] = slice(0,len(eval_period))\n",
    "\n",
    "            self.nse[k] = NSE(data[self.valid_idx[k]])\n",
    "\n",
    "    def evaluate(self,modelled):\n",
    "        qtot_nse = self.nse[self.flow_variable](modelled[self.flow_variable][self.valid_idx[self.flow_variable]])\n",
    "        return np.array(qtot_nse)\n",
    "\n",
    "class TestGlobalSingle:\n",
    "\n",
    "    output_schema = ['objf_val']\n",
    "    objective_key = 'objf_val'\n",
    "\n",
    "    def evaluate(self,l_results):\n",
    "        objf_val = 1.0 - np.mean(l_results['qtot_nse'])\n",
    "        return dict(objf_val = objf_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Kling-Gupta efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "awrams_base_path = os.environ['AWRAMS_BASE_PATH']\n",
    "awrams_base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $awrams_base_path/code/user/awrams_user/objectives/kge_objectives.py\n",
    "import numpy as np\n",
    "\n",
    "from awrams.calibration.support import input_group\n",
    "\n",
    "\n",
    "class KGE:\n",
    "    '''\n",
    "    Precomputed Kling-Gupta Efficiency evaluator\n",
    "    '''    \n",
    "    def __init__(self, obs):\n",
    "        self.obs = obs\n",
    "        # Computing these values during initialisation means we don't have to do so at every iteration\n",
    "        self.obs_sum = np.sum(self.obs)\n",
    "        self.obs_std = np.std(self.obs)\n",
    "\n",
    "    def __call__(self, modelled):\n",
    "        if modelled.size == 0:\n",
    "            correl = np.NaN\n",
    "        else:\n",
    "            correl = np.corrcoef(self.obs, modelled)[0, 1]\n",
    "        alpha = np.std(modelled) / self.obs_std # this is equivalent to np.std(modelled) / np.std(self.obs)\n",
    "        beta = np.sum(modelled) / self.obs_sum\n",
    "        kge = 1 - np.sqrt((correl - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)\n",
    "        return kge\n",
    "\n",
    "# Trial an alternate objective function\n",
    "# Kling-Gupta efficiency\n",
    "class TestLocalSingle_KGE:\n",
    "\n",
    "    input_schema = input_group(['qtot'])\n",
    "    output_schema = ['qtot_kge']\n",
    "\n",
    "    def __init__(self, obs, eval_period):\n",
    "        data = obs['qtot']\n",
    "        \n",
    "        if np.isnan(data).any():\n",
    "            nan_mask = np.isnan(data)\n",
    "            self.valid_idx = np.where(nan_mask==False)\n",
    "        else:\n",
    "            self.valid_idx = slice(0, len(eval_period))\n",
    "\n",
    "        self.kge = KGE(data[self.valid_idx])\n",
    "\n",
    "    def evaluate(self, modelled):\n",
    "        qtot_kge = self.kge(modelled['qtot'][self.valid_idx])\n",
    "        return np.array(qtot_kge)\n",
    "\n",
    "class TestGlobalSingle_KGE:\n",
    "\n",
    "    output_schema = ['objf_val']\n",
    "    objective_key = 'objf_val'\n",
    "\n",
    "    def evaluate(self, l_results):\n",
    "        objf_val = 1.0 - np.mean(l_results['qtot_kge'])\n",
    "        return dict(objf_val=objf_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import your newly created module\n",
    "from awrams_user.objectives import kge_objectives as kobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_objfspec = support.ObjectiveFunctionSpec(kobj.TestLocalSingle_KGE)  # this function to load up the ObjFunc comes from awrams.calibration.support\n",
    "global_objfspec = kobj.TestGlobalSingle_KGE\n",
    "objective_spec = support.ObjectiveSpec(global_objfspec,\n",
    "                                       local_objfspec,\n",
    "                                       observations,\n",
    "                                       eval_period)\n",
    "#### 2.6. Build spec dict\n",
    "#Assemble above settings into specification dictionary\n",
    "# Get the input mapping and model\n",
    "node_mapping = input_map\n",
    "model = awral\n",
    "cal_spec = {}\n",
    "cal_spec['optimizer_spec'] = optimizer_spec\n",
    "cal_spec['objective_spec'] = objective_spec\n",
    "cal_spec['extent_map'] = cal_dict\n",
    "cal_spec['run_period'] = run_period\n",
    "cal_spec['model'] = model\n",
    "cal_spec['node_mapping'] = node_mapping\n",
    "cal_spec['logfile'] = './calres_KGE.h5'\n",
    "ncores = 4\n",
    "nnodes = 1\n",
    "cluster.build_pickle_from_spec(cal_spec, ncores, nnodes, 'test_cal_kge.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the calibration using KGE\n",
    "#from awrams.calibration.launch_calibration import run_from_pickle\n",
    "import time\n",
    "start = time.time()\n",
    "print(\"Starting calibration using KGE........\")\n",
    "cal = run_from_pickle('./test_cal_kge.pkl')\n",
    "end = time.time()\n",
    "print('Calibration complete.......')\n",
    "print('Time elapsed for calibration', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
